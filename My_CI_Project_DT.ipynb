{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_CI_Project_DT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyON7nCcYIsDElMsI2iJJarO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad-nahid-hossain/MSc.-Projects/blob/main/My_CI_Project_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pyKAT2ydyIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5c5d58-827e-4bd7-e974-be12b13e4bd4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0Euq482mI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0096bf9-b3d6-4ada-cbb0-3ca3a8216624"
      },
      "source": [
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 2014_Bodily_Maps_of_Emotions.mat\n",
            "'2019110211_Hossain Mohammad Nahid.gdoc'\n",
            " Books\n",
            "'Books(islamic)'\n",
            "'Bsc Thesis'\n",
            " CERTIFICATES\n",
            "'Colab Notebooks'\n",
            " Coursera\n",
            " CV\n",
            "'Data Acquisition for research work'\n",
            " DeepLearningBook.pdf\n",
            "'Dream forest tour'\n",
            "'Getting started.pdf'\n",
            "'GME transaction'\n",
            " Hmmmmm.gsheet\n",
            "'How to install cuda 10.1 in Ubuntu 18.04.zip'\n",
            " IMG_4717.JPG\n",
            " IMG_4719.JPG\n",
            " lecture_1.pdf\n",
            " lecture_2.pdf\n",
            " lecture_3.pdf\n",
            " lecture_4.pdf\n",
            " Msc\n",
            " Neural-Network-based-finger-counting-technique.pdf\n",
            "'New Doc 2019-09-03 20.05.57.jpg'\n",
            " Paper\n",
            "'PhD Application'\n",
            "'PhD Application Pack'\n",
            "'Planning Document.docx'\n",
            "'Planning Document.odt'\n",
            "'Planning Document.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d-08cgllUFp"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.metrics import confusion_matrix \n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hMvFrESldxE"
      },
      "source": [
        "# Function importing Dataset \n",
        "def importdata():\n",
        "    CI_data = pd.read_csv('/content/drive/My Drive/Msc/Msc Thesis/Coding Documents/WFS/DT/My_Project_CI_data.csv') \n",
        "    # Printing the dataswet shape \n",
        "    print (\"Dataset Length: \", len(CI_data)) \n",
        "    print (\"Dataset Shape: \", CI_data.shape) \n",
        "    \n",
        "    # Printing the dataset obseravtions \n",
        "    print (\"Dataset: \",CI_data.head())\n",
        "    return CI_data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_MKu64xlwng"
      },
      "source": [
        "# Function to split the dataset \n",
        "def splitdataset(CI_data): \n",
        "  \n",
        "    # Separating the target variable \n",
        "    X = CI_data.values[:, 0:7] \n",
        "    Y = CI_data.values[:, 7] \n",
        "  \n",
        "    # Splitting the dataset into train and test \n",
        "    X_train, X_test, y_train, y_test = train_test_split(  \n",
        "    X, Y, test_size = 0.3, random_state = 100) \n",
        "      \n",
        "    return X, Y, X_train, X_test, y_train, y_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbuN43e9l5xP"
      },
      "source": [
        "# Function to perform training with giniIndex. \n",
        "def train_using_gini(X_train, X_test, y_train): \n",
        "  \n",
        "    # Creating the classifier object \n",
        "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
        "            random_state = 100,max_depth=7, min_samples_leaf=1) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_gini.fit(X_train, y_train) \n",
        "    return clf_gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtYtdjQ9mCmK"
      },
      "source": [
        "# Function to perform training with entropy. \n",
        "def tarin_using_entropy(X_train, X_test, y_train): \n",
        "  \n",
        "    # Decision tree with entropy \n",
        "    clf_entropy = DecisionTreeClassifier( \n",
        "            criterion = \"entropy\", random_state = 100, \n",
        "            max_depth = 7, min_samples_leaf = 1) \n",
        "  \n",
        "    # Performing training \n",
        "    clf_entropy.fit(X_train, y_train) \n",
        "    return clf_entropy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCWlfslmHTe"
      },
      "source": [
        "# Function to make predictions \n",
        "def prediction(X_test, clf_object): \n",
        "  \n",
        "    # Predicton on test with giniIndex \n",
        "    y_pred = clf_object.predict(X_test) \n",
        "    print(\"Predicted values:\") \n",
        "    print(y_pred) \n",
        "    return y_pred "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eBF6b8fmLYG"
      },
      "source": [
        "# Function to calculate accuracy \n",
        "def cal_accuracy(y_test, y_pred): \n",
        "      \n",
        "    print(\"Confusion Matrix: \", \n",
        "        confusion_matrix(y_test, y_pred)) \n",
        "      \n",
        "    print (\"Accuracy : \", \n",
        "    accuracy_score(y_test,y_pred)*100) \n",
        "      \n",
        "    print(\"Report : \", \n",
        "    classification_report(y_test, y_pred)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WMYBLqwmPCn"
      },
      "source": [
        "# Driver code \n",
        "def main(): \n",
        "      \n",
        "    # Building Phase \n",
        "    data = importdata() \n",
        "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
        "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
        "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
        "      \n",
        "    # Operational Phase \n",
        "    print(\"Results Using Gini Index:\") \n",
        "      \n",
        "    # Prediction using gini \n",
        "    y_pred_gini = prediction(X_test, clf_gini) \n",
        "    cal_accuracy(y_test, y_pred_gini) \n",
        "      \n",
        "    print(\"Results Using Entropy:\") \n",
        "    # Prediction using entropy \n",
        "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
        "    cal_accuracy(y_test, y_pred_entropy) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWnag5tJmUAP",
        "outputId": "0911d2e5-6bbb-4e9b-f805-65c7a1c27a36"
      },
      "source": [
        "# Calling main function \n",
        "if __name__==\"__main__\": \n",
        "    main() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Length:  5475\n",
            "Dataset Shape:  (5475, 8)\n",
            "Dataset:     TotalTime  EC       AVG      Energy  Sleep  Step  HeartData  Group\n",
            "0         12   2  1.500000  302.500000      8   605         58      3\n",
            "1         13   3  2.166667  183.333333      4   550         58      3\n",
            "2         10   1  1.428571  183.333333      7   550         57      3\n",
            "3         12   2  1.500000  183.333333      5   550         66      3\n",
            "4         10   1  1.250000  201.666667      4   605         79      3\n",
            "Results Using Gini Index:\n",
            "Predicted values:\n",
            "[1. 0. 0. ... 0. 0. 0.]\n",
            "Confusion Matrix:  [[1095    7    8    2]\n",
            " [   5  306    1    2]\n",
            " [ 100   25    2    9]\n",
            " [   0    3    7   71]]\n",
            "Accuracy :  89.71393791844187\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.98      0.95      1112\n",
            "         1.0       0.90      0.97      0.93       314\n",
            "         2.0       0.11      0.01      0.03       136\n",
            "         3.0       0.85      0.88      0.86        81\n",
            "\n",
            "    accuracy                           0.90      1643\n",
            "   macro avg       0.69      0.71      0.69      1643\n",
            "weighted avg       0.84      0.90      0.86      1643\n",
            "\n",
            "Results Using Entropy:\n",
            "Predicted values:\n",
            "[1. 0. 0. ... 0. 0. 0.]\n",
            "Confusion Matrix:  [[1102    5    3    2]\n",
            " [  11  301    1    1]\n",
            " [ 102   25    0    9]\n",
            " [   0    2    2   77]]\n",
            "Accuracy :  90.07912355447353\n",
            "Report :                precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.99      0.95      1112\n",
            "         1.0       0.90      0.96      0.93       314\n",
            "         2.0       0.00      0.00      0.00       136\n",
            "         3.0       0.87      0.95      0.91        81\n",
            "\n",
            "    accuracy                           0.90      1643\n",
            "   macro avg       0.67      0.73      0.70      1643\n",
            "weighted avg       0.83      0.90      0.86      1643\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}